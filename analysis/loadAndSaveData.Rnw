
<<load metadata>>=

#LOAD REQUIRED PACKAGES
require(data.table)
require(plyr)
require(dplyr)

options(scipen=10)
#data_directory<-"/Users/polly/Desktop/projects/heterochromatin/great_ape_diversity/counts/"
data_directory<-"/Users/polly/Desktop/projects/heterochromatin/refactored/" #"/Users/polly/Desktop/projects/heterochromatin/great_ape_diversity/counts75/"
working_directory<-"/Users/polly/Desktop/projects/heterochromatin/refactored/"
setwd(working_directory)

#CHECK IF FILES EXIST
checkExistenceOfFile <- function(file) {
  if (!file.exists(file)) {
    warning(paste("File",file,"does not exist. ERROR."))
  }
}

#list of files that we need to check. Print warning message if non-existent.
invisible(lapply(c("rcounts","layout","contaminated_individuals","related_individuals","rlengths"),checkExistenceOfFile))

#LOAD READ COUNTS
#load read counts after filtering for great apes
readC_afterF = read.table("rcounts",sep=",",header=TRUE) #SRR id followed by read counts after filtering

#LOAD METADATA ABOUT SAMPLES
#Run spots bases LibraryLayout ScientificName SampleName Sex
layout = read.table("layout", header=TRUE, sep = ",")
layout<-layout[layout$Run %in% readC_afterF$Run,] #keep only those that have successful filtering information

#PRINT NUMBER OF DATASETS (NOT INDIVIDUALS) for each species
#print(table(layout$ScientificName,layout$Sex))

#PRINT SIZE OF DATASET FOR EACH INDIVIDUAL
#print(aggregate(layout$bases ~ layout$SampleName + layout$Sex, layout$Sex, FUN=mean))

getFileNames <- function(sex=NULL,species=NULL,name=NULL){
  #print(sex) 
  #print(species) 
  #print(name)
  list <-layout
  if (!is.null(sex)) {list <-list[list$Sex==sex,]}
  if (!is.null(species)) {list <-list[list$ScientificName==species,]}
  if (!is.null(name)) {list <-list[list$SampleName==name,]}
  filenames<-paste(list$Run,gsub(" ","_", list$ScientificName),gsub(" ","_", list$SampleName),list$Sex,"1.fastq",sep="|")
  #print(list)
  return(filenames) #includes only R1 files
}

getFilteredReadCounts <- function(files) {
  SRR_ids<-gsub( "\\|.*$", "", files)
  merged<-merge(SRR_ids,readC_afterF,by=1)
  read_counts<-merged[match(SRR_ids,merged$x),]$rCount
  
  if (!length(SRR_ids)==length(read_counts)) {
    stop("Discrepancies in the association table.")
  }
  
  if (any(is.na(read_counts))) {
    stop("Discrepancies in the read length association.")
  }
  
  return(read_counts)
}

getReadLengths <- function(files) {
  SRR_ids<-gsub( "\\|.*$", "", files)
  merged<-merge(SRR_ids,read_lengths,by=1)
  rl<-merged[match(SRR_ids,merged$x),]$read_length
  
  if (!length(SRR_ids)==length(rl)) {
    stop("Discrepancies in the association table.")
  }
  
  if (any(is.na(rl))) {
    stop("Discrepancies in the read length association.")
  }
  
  return(rl)
}


#filters = list(species="Pan paniscus")
filters = list() #no filters here, however filters could be potentially specified

#GET LIST OF ALL DATASETS AVAILABLE
files<-do.call(getFileNames, filters)

# get the size for each file
#sizes <- file.info(list.files(data_directory,full.names=TRUE))

# subset the files that have non-zero size
#list.of.non.empty.files <- basename(rownames(sizes[sizes$size>0,]))

#files<-files[gsub("\\|","_",files) %in% list.of.non.empty.files] #keep only non-empty files
@


<<load data from previous section, keep only those datasets/individuals that pass filters>>=

dropLowReadCounts <-function(files,read_count_threshold) {
  if (!length(getFilteredReadCounts(files))==length(files)) {
    stop("Discrepancies in the read length association.")
  }
  keep<-getFilteredReadCounts(files)>read_count_threshold
  print(paste("excluding this many files:",as.numeric(table(keep)["FALSE"])))
  print(paste("returning this many files:",as.numeric(table(keep)["TRUE"])))
  return(files[keep])
}

dropShortReads <-function(files,read_length_threshold) { 
  SRR_ids<-gsub("\\|.*$", "",files)
  merged<-merge(SRR_ids,read_lengths,by=1)
  colnames(merged)<-c("file","read_length")
  read_lens<-merged[match(SRR_ids,merged$file),]$read_length
  
  if (!length(files)==length(read_lens)) {
    stop("Discrepancies in the read length association.")
  }
  
  if (any(is.na(read_lens))) {
    stop("Discrepancies in the read length association.")
  }
  
  print(read_length_threshold)
  SRR_ids_to_exclude<-read_lengths[read_lengths$read_length<read_length_threshold,]$file
  SRR_ids_to_keep<-read_lengths[read_lengths$read_length>=read_length_threshold,]$file
  
  print(paste("excluding this many files:",length(SRR_ids_to_exclude)))
  if (length(SRR_ids_to_exclude)==0) {
      print(paste("returning this many files:",length(files)))
      return(files)
  } else {
      keep<-gsub("\\|.*","",files) %in% SRR_ids_to_keep
      print(paste("returning this many files:",length(files[keep])))
      return(files[keep])
  }
}

dropContaminatedFiles <-function(files) {
  keep<-!grepl(paste(unlist(contaminated),collapse="|"),files)
  print(paste("excluding this many files:",as.numeric(table(keep)["FALSE"])))
  print(paste("returning this many files:",as.numeric(table(keep)["TRUE"])))
  return(files[keep])
}

dropFamilyRelatedFiles <-function(files) {
  keep<-!grepl(paste(unlist(related),collapse="|"),files)
  print(paste("excluding this many files:",as.numeric(table(keep)["FALSE"])))
  print(paste("returning this many files:",as.numeric(table(keep)["TRUE"])))
  return(files[keep])
}

contaminated = read.table("contaminated_individuals", header=FALSE)
related = read.table("related_individuals", header=FALSE)
read_lengths = as.data.frame(read.table("rlengths", sep=",",header=TRUE))
read_lengths<-read_lengths[grep("1.fastq",read_lengths$file),] #keep only forward reads
read_lengths$file<-gsub("_.*","",read_lengths$file)
read_lengths$file<-gsub('[.].*',"",read_lengths$file)

filtered_files<-files

#drop files with too short reads
filtered_files<-dropShortReads(filtered_files,52) #exclude everything shorter than a given threshold

#drop files with very low read counts
filtered_files<-dropLowReadCounts(filtered_files,20000000) #threshold representing minimal number of reads for sample to be taken into consideration

#drop contaminated individuals
#filtered_files<-dropContaminatedFiles(filtered_files)

#drop related individuals that could bias heterochromatin abundance counts
filtered_files<-dropFamilyRelatedFiles(filtered_files)
@

<<FREQUENCY>>=
#d<-read.table("/Users/polly/Desktop/projects/heterochromatin/great_ape_diversity/counts75/threshold100/sort/big.table.with.header.txt",sep=" ",header=TRUE,row.names=1,na.strings=NA,fill=TRUE)
  
d<-read.table("/Users/polly/Desktop/projects/heterochromatin/refactored/big.table.with.header.rawcounts.sortedFilt.txt",sep=" ",header=TRUE,row.names=1,na.strings=NA,fill=TRUE)
d<-as.data.frame(d) #convert to dataframe
d[is.na(d)] <- 0

columns_to_select<-paste0(gsub( "\\|", "_",filtered_files),".dat_Header.txt.rawcounts.sortedFilt")
data<-d[order(-rowSums(d)),columns_to_select] 
#View(d)

rep.row<-function(x,n){
   matrix(rep(x,each=n),nrow=n) #transforms normalization vector into matrix
}

#NORMALIZE BY READ COUNTS per million reads
normalization_factor=1000000
normalization_matrix<-rep.row(getFilteredReadCounts(filtered_files),dim(data)[1])
data<-as.data.frame(data) #convert to dataframe from data table
data<-data/normalization_matrix*normalization_factor #normalization of data by read counts

#NORMALIZE BY READ LENGTH per 100bp reads
normalization_factor=100
normalization_matrix<-rep.row(getReadLengths(filtered_files),dim(data)[1])
data<-as.data.frame(data) #convert to dataframe from data table
data<-data/normalization_matrix*normalization_factor #normalization of data by read counts

#FREQUENCY
frequency<-data[,columns_to_select] #RESTRICT ONLY TO FILTERED FILES
frequency<-frequency[order(rowSums(frequency),decreasing=T),]
frequency<-frequency[nchar(as.character(rownames(frequency)))<=50,] #remove handful of repeat motifs with unit sizes over 50
frequency<-as.data.frame(frequency)

plot(table(nchar(as.character(rownames(frequency)))),ylab="number of distinct repeat motifs",xlab="unit size")
@

<<DENSITY>>=
d<-read.table("/Users/polly/Desktop/projects/heterochromatin/refactored/big.table.with.header.rawlengths.sortedFilt.txt",sep=" ",header=TRUE,row.names=1,na.strings=NA,fill=TRUE)
d<-as.data.frame(d) #convert to dataframe
d[is.na(d)] <- 0

columns_to_select<-paste0(gsub( "\\|", "_",filtered_files),".dat_Header.txt.rawlengths.sortedFilt")
data<-d[order(-rowSums(d)),columns_to_select] 
#View(d)

rep.row<-function(x,n){
   matrix(rep(x,each=n),nrow=n) #transforms normalization vector into matrix
}

#NORMALIZE BY READ COUNTS
normalization_factor=1000000
normalization_matrix<-rep.row(getFilteredReadCounts(filtered_files),dim(data)[1])
data<-as.data.frame(data) #convert to dataframe from data table
data<-data/normalization_matrix*normalization_factor #normalization of data by read counts

#NORMALIZE BY READ LENGTH
normalization_factor=100
normalization_matrix<-rep.row(getReadLengths(filtered_files),dim(data)[1])
data<-as.data.frame(data) #convert to dataframe from data table
data<-data/normalization_matrix*normalization_factor #normalization of data by read counts

#DENSITY
density<-data[rownames(frequency),columns_to_select] #restrict only to filtered files and match filtering of frequency variable

plot(table(nchar(as.character(rownames(density)))),ylab="number of distinct repeat motifs",xlab="unit size")
@

<<stat>>=
print(dim(frequency))
print(dim(density))
@

<<load plotting functions>>=
my.vioplot=function (x, ..., range = 1.5, h = NULL, ylim = NULL, names = NULL, 
    horizontal = FALSE, col = "magenta", border = "black", lty = 1, 
    lwd = 1, rectCol = "black", colMed = "white", pchMed = 19, 
    at, add = FALSE, wex = 1, drawRect = TRUE) 
{
    datas <- list(x, ...)
    n <- length(datas)
    if (missing(at)) 
        at <- 1:n
    upper <- vector(mode = "numeric", length = n)
    lower <- vector(mode = "numeric", length = n)
    q1 <- vector(mode = "numeric", length = n)
    q3 <- vector(mode = "numeric", length = n)
    med <- vector(mode = "numeric", length = n)
    base <- vector(mode = "list", length = n)
    height <- vector(mode = "list", length = n)
    baserange <- c(Inf, -Inf)
    args <- list(display = "none")
    if (!(is.null(h))) 
        args <- c(args, h = h)
    for (i in 1:n) {
        data <- datas[[i]]
        data.min <- min(data)
        data.max <- max(data)
        q1[i] <- quantile(data, 0.25)
        q3[i] <- quantile(data, 0.75)
        med[i] <- median(data)
        iqd <- q3[i] - q1[i]
        upper[i] <- min(q3[i] + range * iqd, data.max)
        lower[i] <- max(q1[i] - range * iqd, data.min)
        est.xlim <- c(min(lower[i], data.min), max(upper[i], 
            data.max))
        smout <- do.call("sm.density", c(list(data, xlim = est.xlim), 
            args))
        hscale <- 0.4/max(smout$estimate) * wex
        base[[i]] <- smout$eval.points
        height[[i]] <- smout$estimate * hscale
        t <- range(base[[i]])
        baserange[1] <- min(baserange[1], t[1])
        baserange[2] <- max(baserange[2], t[2])
    }
    if (!add) {
        xlim <- if (n == 1) 
            at + c(-0.5, 0.5)
        else range(at) + min(diff(at))/2 * c(-1, 1)
        if (is.null(ylim)) {
            ylim <- baserange
        }
    }
    if (is.null(names)) {
        label <- 1:n
    }
    else {
        label <- names
    }
    boxwidth <- 0.05 * wex
    if (!add) 
        plot.new()
    if (!horizontal) {
        if (!add) {
            plot.window(xlim = xlim, ylim = ylim)
            axis(2)
            axis(1, at = at, label = label)
        }
        box()
        for (i in 1:n) {
            polygon(c(at[i] - height[[i]], rev(at[i] + height[[i]])), 
                c(base[[i]], rev(base[[i]])), col = col[i], border = border, 
                lty = lty, lwd = lwd)
            if (drawRect) {
                lines(at[c(i, i)], c(lower[i], upper[i]), lwd = lwd, 
                  lty = lty)
                rect(at[i] - boxwidth/2, q1[i], at[i] + boxwidth/2, 
                  q3[i], col = rectCol)
                points(at[i], med[i], pch = pchMed, col = colMed)
            }
        }
    }
    else {
        if (!add) {
            plot.window(xlim = ylim, ylim = xlim)
            axis(1)
            axis(2, at = at, label = label)
        }
        box()
        for (i in 1:n) {
            polygon(c(base[[i]], rev(base[[i]])), c(at[i] - height[[i]], 
                rev(at[i] + height[[i]])), col = col[i], border = border, 
                lty = lty, lwd = lwd)
            if (drawRect) {
                lines(c(lower[i], upper[i]), at[c(i, i)], lwd = lwd, 
                  lty = lty)
                rect(q1[i], at[i] - boxwidth/2, q3[i], at[i] + 
                  boxwidth/2, col = rectCol)
                points(med[i], at[i], pch = pchMed, col = colMed)
            }
        }
    }
    invisible(list(upper = upper, lower = lower, median = med, 
        q1 = q1, q3 = q3))
}
@
